
# RAG Application

This project is a Retrieval Augmented Generation (RAG) application built with Streamlit, Langchain, and Ollama. It allows users to upload documents (PDF, DOCX, TXT), ask questions about their content, and get answers generated by a local Large Language Model (LLM) powered by Ollama.

## Features

*   **Document Upload:** Supports PDF, DOCX, and TXT file formats.
*   **Vector Store Creation:** Creates and updates a FAISS vector store from uploaded documents for efficient retrieval.
*   **Question Answering:** Users can ask questions, and the application retrieves relevant context from the documents to generate answers using an LLM.
*   **Source Documents:** Displays snippets of source documents used to generate the answer.
*   **Local LLM:** Utilizes Ollama to run LLMs locally (e.g., `qwen3:4b`).
*   **Data Management:**
    *   Clear uploaded files.
    *   Clear the vector store.
*   **Configurable:** Easy to change Ollama model and base URL via a configuration file.

## Project Structure

